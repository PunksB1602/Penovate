{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid CNN-BiLSTM Framework for Real-Time Handwriting Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Union\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reproducibility, Data Loading, and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def load_raw_splits(data_dir: Path):\n",
    "    X_train = np.load(data_dir / \"X_train.npy\")\n",
    "    X_val   = np.load(data_dir / \"X_val.npy\")\n",
    "    X_test  = np.load(data_dir / \"X_test.npy\")\n",
    "    y_train = np.load(data_dir / \"y_train.npy\", allow_pickle=True)\n",
    "    y_val   = np.load(data_dir / \"y_val.npy\", allow_pickle=True)\n",
    "    y_test  = np.load(data_dir / \"y_test.npy\", allow_pickle=True)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def encode_labels(y_train, y_val, y_test, save_path: Path):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(np.unique(np.concatenate([y_train, y_val, y_test])))\n",
    "    y_train_enc = le.transform(y_train).astype(int)\n",
    "    y_val_enc   = le.transform(y_val).astype(int)\n",
    "    y_test_enc  = le.transform(y_test).astype(int)\n",
    "    np.save(save_path, le.classes_)\n",
    "    return y_train_enc, y_val_enc, y_test_enc, le.classes_\n",
    "\n",
    "def make_loaders(X_train, y_train, X_val, y_val, X_test, y_test, batch_size: int):\n",
    "    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                             torch.tensor(y_train, dtype=torch.long))\n",
    "    val_ds   = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                             torch.tensor(y_val, dtype=torch.long))\n",
    "    test_ds  = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                             torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int = 18,\n",
    "        num_classes: int = 26,\n",
    "        hidden_size: int = 128,\n",
    "        dropout: float = 0.3,\n",
    "        use_batchnorm: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(num_features, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64) if use_batchnorm else nn.Identity()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128) if use_batchnorm else nn.Identity()\n",
    "\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=128,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, 128)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    data_dir: Path\n",
    "    out_dir: Path\n",
    "    num_features: int = 18\n",
    "    num_classes: int = 26\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 50\n",
    "    dropout: float = 0.3\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-4\n",
    "    step_size: int = 10\n",
    "    gamma: float = 0.8\n",
    "    patience: int = 10\n",
    "    seed: int = 42\n",
    "    use_batchnorm: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Trainer Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, device, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return running_loss / max(1, len(loader)), correct / max(1, total)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    loss_sum = 0.0\n",
    "    correct, total = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        y_true.append(y.cpu().numpy())\n",
    "        y_pred.append(pred.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true) if y_true else np.array([])\n",
    "    y_pred = np.concatenate(y_pred) if y_pred else np.array([])\n",
    "    return loss_sum / max(1, len(loader)), correct / max(1, total), y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves_csv(\n",
    "    log_csv: Path,\n",
    "    out_dir: Path,\n",
    "    prefix: str,\n",
    "    *,\n",
    "    ema: Optional[float] = None,\n",
    "    figsize=(3.5, 2.4),\n",
    "    dpi: int = 600,\n",
    "    use_color: bool = False,\n",
    "    show_grid: bool = False,\n",
    "    acc_in_percent: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss/accuracy curves. Saves PDF and PNG.\n",
    "    Expects columns: epoch, train_loss, val_loss, train_acc, val_acc\n",
    "    \"\"\"\n",
    "\n",
    "    with mpl.rc_context({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"STIXGeneral\", \"DejaVu Serif\"],\n",
    "        \"mathtext.fontset\": \"stix\",\n",
    "        \"font.size\": 10,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"legend.fontsize\": 9,\n",
    "        \"xtick.labelsize\": 9,\n",
    "        \"ytick.labelsize\": 9,\n",
    "        \"lines.linewidth\": 1.6,\n",
    "        \"axes.linewidth\": 1.0,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"xtick.minor.visible\": True,\n",
    "        \"ytick.minor.visible\": True,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": show_grid,\n",
    "        \"grid.alpha\": 0.15,\n",
    "        \"grid.linestyle\": \"--\",\n",
    "        \"grid.linewidth\": 0.6,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"savefig.pad_inches\": 0.02,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "    }):\n",
    "        log_csv = Path(log_csv)\n",
    "        out_dir = Path(out_dir)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        df = pd.read_csv(log_csv)\n",
    "        req = [\"epoch\", \"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\"]\n",
    "        missing = [c for c in req if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns in {log_csv}: {missing}\")\n",
    "\n",
    "        x = df[\"epoch\"].to_numpy(dtype=float)\n",
    "\n",
    "        def smooth(y: np.ndarray) -> np.ndarray:\n",
    "            y = np.asarray(y, dtype=float)\n",
    "            if ema is None:\n",
    "                return y\n",
    "            a = float(ema)\n",
    "            if not (0.0 < a < 1.0):\n",
    "                raise ValueError(\"ema must be in (0,1) or None\")\n",
    "            ys = np.empty_like(y, dtype=float)\n",
    "            ys[0] = y[0]\n",
    "            for i in range(1, len(y)):\n",
    "                ys[i] = a * y[i] + (1.0 - a) * ys[i - 1]\n",
    "            return ys\n",
    "\n",
    "        tr_loss = smooth(df[\"train_loss\"].to_numpy())\n",
    "        va_loss = smooth(df[\"val_loss\"].to_numpy())\n",
    "        tr_acc  = smooth(df[\"train_acc\"].to_numpy())\n",
    "        va_acc  = smooth(df[\"val_acc\"].to_numpy())\n",
    "\n",
    "        if acc_in_percent:\n",
    "            tr_acc *= 100.0\n",
    "            va_acc *= 100.0\n",
    "\n",
    "        if use_color:\n",
    "            c_train, c_val = \"#004488\", \"#DDAA33\"\n",
    "        else:\n",
    "            c_train, c_val = \"black\", \"black\"\n",
    "\n",
    "        def finalize_axes(ax: plt.Axes):\n",
    "            ax.tick_params(which=\"both\", top=False, right=False)\n",
    "            ax.set_xlim(float(np.min(x)), float(np.max(x)))\n",
    "\n",
    "        def save(fig: plt.Figure, base: Path):\n",
    "            fig.savefig(base.with_suffix(\".pdf\"))\n",
    "            fig.savefig(base.with_suffix(\".png\"), dpi=dpi)\n",
    "            plt.close(fig)\n",
    "\n",
    "        # Loss curve\n",
    "        fig, ax = plt.subplots(figsize=figsize, constrained_layout=True)\n",
    "        ax.plot(x, tr_loss, color=c_train, linestyle=\"-\",  marker=None, label=\"Train\")\n",
    "        ax.plot(x, va_loss, color=c_val,   linestyle=\"--\", marker=None, label=\"Validation\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "        ax.legend(frameon=False, loc=\"best\")\n",
    "        finalize_axes(ax)\n",
    "        save(fig, out_dir / f\"{prefix}_loss\")\n",
    "\n",
    "        # Accuracy curve\n",
    "        fig, ax = plt.subplots(figsize=figsize, constrained_layout=True)\n",
    "        ax.plot(x, tr_acc, color=c_train, linestyle=\"-\",  marker=None, label=\"Train\")\n",
    "        ax.plot(x, va_acc, color=c_val,   linestyle=\"--\", marker=None, label=\"Validation\")\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Accuracy (%)\" if acc_in_percent else \"Accuracy\")\n",
    "        if acc_in_percent:\n",
    "            ax.set_ylim(0.0, 100.0)\n",
    "        else:\n",
    "            ax.set_ylim(0.0, 1.0)\n",
    "        ax.legend(frameon=False, loc=\"best\")\n",
    "        finalize_axes(ax)\n",
    "        save(fig, out_dir / f\"{prefix}_accuracy\")\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    y_true: Union[Sequence[int], np.ndarray],\n",
    "    y_pred: Union[Sequence[int], np.ndarray],\n",
    "    out_path: Path,\n",
    "    *,\n",
    "    class_names: Optional[Sequence[str]] = None,\n",
    "    labels: Optional[Sequence[int]] = None,\n",
    "    normalize: bool = True,\n",
    "    show_counts: bool = True,\n",
    "    min_show_pct: float = 2.0,\n",
    "    dpi: int = 600,\n",
    "    cmap=\"Blues\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix. Saves PDF and PNG. If normalize=True, values are in %.\n",
    "    \"\"\"\n",
    "\n",
    "    with mpl.rc_context({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times New Roman\", \"STIXGeneral\", \"DejaVu Serif\"],\n",
    "        \"mathtext.fontset\": \"stix\",\n",
    "        \"font.size\": 9,\n",
    "        \"axes.titlesize\": 10,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"axes.linewidth\": 1.0,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"savefig.bbox\": \"tight\",\n",
    "        \"savefig.pad_inches\": 0.02,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "    }):\n",
    "        out_path = Path(out_path)\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        y_true = np.asarray(y_true, dtype=int).reshape(-1)\n",
    "        y_pred = np.asarray(y_pred, dtype=int).reshape(-1)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = np.unique(np.concatenate([y_true, y_pred])).tolist()\n",
    "        labels = list(labels)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels).astype(float)\n",
    "\n",
    "        if class_names is None:\n",
    "            class_names = [str(l) for l in labels]\n",
    "        else:\n",
    "            if len(class_names) != len(labels):\n",
    "                raise ValueError(\"len(class_names) must match len(labels)\")\n",
    "            class_names = [str(c) for c in class_names]\n",
    "\n",
    "        if normalize:\n",
    "            row_sums = cm.sum(axis=1, keepdims=True)\n",
    "            row_sums[row_sums == 0] = 1.0\n",
    "            cm_show = (cm / row_sums) * 100.0\n",
    "        else:\n",
    "            cm_show = cm\n",
    "\n",
    "        n = len(labels)\n",
    "        fig_w = min(6.8, max(3.8, 0.45 * n + 1.6))\n",
    "        fig_h = min(6.8, max(3.4, 0.45 * n + 1.3))\n",
    "        fig, ax = plt.subplots(figsize=(fig_w, fig_h), constrained_layout=True)\n",
    "\n",
    "        im = ax.imshow(cm_show, interpolation=\"nearest\", cmap=cmap, aspect=\"equal\")\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "        if normalize:\n",
    "            cbar.set_label(\"%\", fontsize=9)\n",
    "\n",
    "        ax.set_title(\"Confusion Matrix\" + (\" (Row-normalized)\" if normalize else \"\"))\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "\n",
    "        ticks = np.arange(n)\n",
    "        ax.set_xticks(ticks)\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "        ax.set_yticklabels(class_names)\n",
    "\n",
    "        bbox_kw = dict(\n",
    "            boxstyle=\"round,pad=0.15\",\n",
    "            facecolor=\"white\",\n",
    "            edgecolor=\"none\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                cnt = cm[i, j]\n",
    "\n",
    "                if normalize:\n",
    "                    pct = float(cm_show[i, j])\n",
    "                    if pct < float(min_show_pct):\n",
    "                        continue\n",
    "                    text = f\"{pct:.1f}%\"\n",
    "                    if show_counts:\n",
    "                        text += f\"\\n({int(cnt)})\"\n",
    "                else:\n",
    "                    if cnt == 0:\n",
    "                        continue\n",
    "                    text = f\"{int(cnt)}\"\n",
    "\n",
    "                ax.text(\n",
    "                    j, i, text,\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    fontsize=8 if n <= 8 else 7,\n",
    "                    color=\"black\",\n",
    "                    bbox=bbox_kw,\n",
    "                )\n",
    "\n",
    "        out_base = out_path.with_suffix(\"\")\n",
    "        fig.savefig(out_base.with_suffix(\".pdf\"))\n",
    "        fig.savefig(out_base.with_suffix(\".png\"), dpi=dpi)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, cfg: TrainConfig):\n",
    "        self.cfg = cfg\n",
    "        cfg.out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        seed_everything(cfg.seed)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Data\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = load_raw_splits(cfg.data_dir)\n",
    "        y_train, y_val, y_test, self.class_names = encode_labels(\n",
    "            y_train, y_val, y_test, save_path=cfg.data_dir / \"label_encoder.npy\"\n",
    "        )\n",
    "        self.train_loader, self.val_loader, self.test_loader = make_loaders(\n",
    "            X_train, y_train, X_val, y_val, X_test, y_test, cfg.batch_size\n",
    "        )\n",
    "\n",
    "        # Model and optimizer\n",
    "        self.model = CNN_BiLSTM(\n",
    "            num_features=cfg.num_features,\n",
    "            num_classes=cfg.num_classes,\n",
    "            hidden_size=128,\n",
    "            dropout=cfg.dropout,\n",
    "            use_batchnorm=cfg.use_batchnorm\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=cfg.step_size, gamma=cfg.gamma)\n",
    "\n",
    "        self.best_val_acc = -1.0\n",
    "        self.best_path = cfg.out_dir / (\"best_bn.pth\" if cfg.use_batchnorm else \"best_no_bn.pth\")\n",
    "        self.log_path  = cfg.out_dir / (\"train_log_bn.csv\" if cfg.use_batchnorm else \"train_log_no_bn.csv\")\n",
    "\n",
    "    def fit(self):\n",
    "        patience_left = self.cfg.patience\n",
    "        rows = []\n",
    "\n",
    "        for epoch in range(1, self.cfg.epochs + 1):\n",
    "            tr_loss, tr_acc = train_one_epoch(self.model, self.train_loader, self.device, self.criterion, self.optimizer)\n",
    "            val_loss, val_acc, _, _ = evaluate(self.model, self.val_loader, self.device, self.criterion)\n",
    "\n",
    "            rows.append({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": tr_loss,\n",
    "                \"train_acc\": tr_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"lr\": self.optimizer.param_groups[0][\"lr\"],\n",
    "            })\n",
    "            pd.DataFrame(rows).to_csv(self.log_path, index=False)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch}/{self.cfg.epochs} | \"\n",
    "                f\"train_loss={tr_loss:.4f} train_acc={tr_acc:.4f} | \"\n",
    "                f\"val_loss={val_loss:.4f} val_acc={val_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                torch.save(self.model.state_dict(), self.best_path)\n",
    "                patience_left = self.cfg.patience\n",
    "            else:\n",
    "                patience_left -= 1\n",
    "                if patience_left <= 0:\n",
    "                    print(f\"Early stopping at epoch {epoch} (best val_acc={self.best_val_acc:.4f})\")\n",
    "                    break\n",
    "\n",
    "            self.scheduler.step()\n",
    "\n",
    "        return self.log_path\n",
    "\n",
    "    def test(self):\n",
    "        self.model.load_state_dict(torch.load(self.best_path, map_location=self.device))\n",
    "        test_loss, test_acc, y_true, y_pred = evaluate(self.model, self.test_loader, self.device, self.criterion)\n",
    "\n",
    "        report_txt = classification_report(\n",
    "            y_true, y_pred,\n",
    "            digits=4,\n",
    "            zero_division=0,\n",
    "            target_names=[str(c) for c in self.class_names]\n",
    "        )\n",
    "        (self.cfg.out_dir / \"classification_report.txt\").write_text(\n",
    "            f\"Best val_acc: {self.best_val_acc:.4f}\\n\"\n",
    "            f\"Test loss: {test_loss:.4f}\\n\"\n",
    "            f\"Test acc: {test_acc:.4f}\\n\\n\"\n",
    "            f\"{report_txt}\\n\"\n",
    "        )\n",
    "\n",
    "        np.save(self.cfg.out_dir / \"y_true_test.npy\", y_true)\n",
    "        np.save(self.cfg.out_dir / \"y_pred_test.npy\", y_pred)\n",
    "\n",
    "        print(f\"Test: loss={test_loss:.4f} acc={test_acc:.4f}\")\n",
    "        return test_loss, test_acc, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_data():\n",
    "    X_train = np.load(\"X_train.npy\")\n",
    "    y_train = np.load(\"y_train.npy\", allow_pickle=True)\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"y_train sample:\", y_train[:5])\n",
    "    print(\"Label range:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | train_loss=3.2621 train_acc=0.0362 | val_loss=3.2587 val_acc=0.0385\n",
      "Epoch 2/50 | train_loss=3.2607 train_acc=0.0307 | val_loss=3.2588 val_acc=0.0385\n",
      "Epoch 3/50 | train_loss=3.2605 train_acc=0.0348 | val_loss=3.2583 val_acc=0.0385\n",
      "Epoch 4/50 | train_loss=3.2600 train_acc=0.0370 | val_loss=3.2582 val_acc=0.0385\n",
      "Epoch 5/50 | train_loss=3.2572 train_acc=0.0407 | val_loss=3.2328 val_acc=0.0503\n",
      "Epoch 6/50 | train_loss=3.2343 train_acc=0.0451 | val_loss=3.0799 val_acc=0.0592\n",
      "Epoch 7/50 | train_loss=2.8650 train_acc=0.0936 | val_loss=2.6213 val_acc=0.1272\n",
      "Epoch 8/50 | train_loss=2.6340 train_acc=0.1309 | val_loss=2.5416 val_acc=0.1243\n",
      "Epoch 9/50 | train_loss=2.5658 train_acc=0.1402 | val_loss=2.4423 val_acc=0.1568\n",
      "Epoch 10/50 | train_loss=2.4569 train_acc=0.1612 | val_loss=2.3268 val_acc=0.1864\n",
      "Epoch 11/50 | train_loss=2.3725 train_acc=0.1775 | val_loss=2.2629 val_acc=0.2189\n",
      "Epoch 12/50 | train_loss=2.2718 train_acc=0.1993 | val_loss=2.2299 val_acc=0.2278\n",
      "Epoch 13/50 | train_loss=2.2313 train_acc=0.2075 | val_loss=2.3928 val_acc=0.1834\n",
      "Epoch 14/50 | train_loss=2.1368 train_acc=0.2141 | val_loss=2.1836 val_acc=0.2278\n",
      "Epoch 15/50 | train_loss=2.1039 train_acc=0.2419 | val_loss=2.3108 val_acc=0.1982\n",
      "Epoch 16/50 | train_loss=2.0223 train_acc=0.2555 | val_loss=1.9493 val_acc=0.2811\n",
      "Epoch 17/50 | train_loss=1.9062 train_acc=0.2988 | val_loss=1.8886 val_acc=0.3432\n",
      "Epoch 18/50 | train_loss=1.7971 train_acc=0.3199 | val_loss=1.8423 val_acc=0.3254\n",
      "Epoch 19/50 | train_loss=1.7576 train_acc=0.3277 | val_loss=1.7978 val_acc=0.3728\n",
      "Epoch 20/50 | train_loss=1.7116 train_acc=0.3495 | val_loss=1.7534 val_acc=0.3817\n",
      "Epoch 21/50 | train_loss=1.5544 train_acc=0.4087 | val_loss=1.5105 val_acc=0.4763\n",
      "Epoch 22/50 | train_loss=1.3539 train_acc=0.4804 | val_loss=1.5217 val_acc=0.5089\n",
      "Epoch 23/50 | train_loss=1.2658 train_acc=0.5115 | val_loss=1.3147 val_acc=0.5947\n",
      "Epoch 24/50 | train_loss=1.1450 train_acc=0.5725 | val_loss=1.2347 val_acc=0.6036\n",
      "Epoch 25/50 | train_loss=1.0243 train_acc=0.6076 | val_loss=1.0558 val_acc=0.6686\n",
      "Epoch 26/50 | train_loss=0.8684 train_acc=0.6831 | val_loss=0.8943 val_acc=0.7337\n",
      "Epoch 27/50 | train_loss=0.7480 train_acc=0.7404 | val_loss=0.7253 val_acc=0.7988\n",
      "Epoch 28/50 | train_loss=0.6623 train_acc=0.7870 | val_loss=0.9158 val_acc=0.7840\n",
      "Epoch 29/50 | train_loss=0.5342 train_acc=0.8410 | val_loss=0.6068 val_acc=0.8639\n",
      "Epoch 30/50 | train_loss=0.4457 train_acc=0.8724 | val_loss=0.4961 val_acc=0.8905\n",
      "Epoch 31/50 | train_loss=0.3493 train_acc=0.9075 | val_loss=0.4085 val_acc=0.9201\n",
      "Epoch 32/50 | train_loss=0.2976 train_acc=0.9271 | val_loss=0.6948 val_acc=0.8905\n",
      "Epoch 33/50 | train_loss=0.2705 train_acc=0.9345 | val_loss=0.5038 val_acc=0.9231\n",
      "Epoch 34/50 | train_loss=0.2257 train_acc=0.9497 | val_loss=0.4144 val_acc=0.9408\n",
      "Epoch 35/50 | train_loss=0.1937 train_acc=0.9582 | val_loss=0.4871 val_acc=0.9142\n",
      "Epoch 36/50 | train_loss=0.1478 train_acc=0.9719 | val_loss=0.3078 val_acc=0.9645\n",
      "Epoch 37/50 | train_loss=0.1427 train_acc=0.9693 | val_loss=0.3284 val_acc=0.9615\n",
      "Epoch 38/50 | train_loss=0.1259 train_acc=0.9734 | val_loss=0.5442 val_acc=0.9142\n",
      "Epoch 39/50 | train_loss=0.1449 train_acc=0.9678 | val_loss=0.3752 val_acc=0.9497\n",
      "Epoch 40/50 | train_loss=0.1189 train_acc=0.9730 | val_loss=0.3545 val_acc=0.9586\n",
      "Epoch 41/50 | train_loss=0.0893 train_acc=0.9811 | val_loss=0.3531 val_acc=0.9556\n",
      "Epoch 42/50 | train_loss=0.0701 train_acc=0.9882 | val_loss=0.3359 val_acc=0.9615\n",
      "Epoch 43/50 | train_loss=0.0570 train_acc=0.9889 | val_loss=0.5078 val_acc=0.9379\n",
      "Epoch 44/50 | train_loss=0.0801 train_acc=0.9856 | val_loss=0.3078 val_acc=0.9704\n",
      "Epoch 45/50 | train_loss=0.0459 train_acc=0.9904 | val_loss=0.3668 val_acc=0.9615\n",
      "Epoch 46/50 | train_loss=0.0494 train_acc=0.9885 | val_loss=0.3995 val_acc=0.9615\n",
      "Epoch 47/50 | train_loss=0.0512 train_acc=0.9915 | val_loss=0.3167 val_acc=0.9704\n",
      "Epoch 48/50 | train_loss=0.0403 train_acc=0.9896 | val_loss=0.3609 val_acc=0.9675\n",
      "Epoch 49/50 | train_loss=0.0374 train_acc=0.9911 | val_loss=0.3074 val_acc=0.9822\n",
      "Epoch 50/50 | train_loss=0.0492 train_acc=0.9908 | val_loss=0.6170 val_acc=0.9379\n",
      "Test: loss=0.5585 acc=0.9645\n",
      "Training complete.\n",
      "Outputs saved to: outputs\\cnn_bilstm_bn_drop05_seed123_run\n",
      "Training log: outputs\\cnn_bilstm_bn_drop05_seed123_run\\train_log_bn.csv\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate():\n",
    "    DATA_DIR = Path(\".\")\n",
    "    OUT_DIR  = Path(\"outputs/cnn_bilstm_no_bn_drop05_seed42_run\")\n",
    "\n",
    "    cfg = TrainConfig(\n",
    "        data_dir=DATA_DIR,\n",
    "        out_dir=OUT_DIR,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        use_batchnorm=False,\n",
    "        dropout=0.5,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(cfg)\n",
    "    log_csv = trainer.fit()\n",
    "    trainer.test()\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    print(\"Outputs saved to:\", cfg.out_dir)\n",
    "    print(\"Training log:\", log_csv)\n",
    "\n",
    "train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots generated successfully.\n"
     ]
    }
   ],
   "source": [
    "def plot_results_only():\n",
    "    DATA_DIR = Path(\".\")\n",
    "    OUT_DIR  = Path(\"outputs/cnn_bilstm_no_bn_drop05_seed42_run\")\n",
    "\n",
    "    log_csv = OUT_DIR / \"train_log_bn.csv\"\n",
    "\n",
    "    y_true = np.load(OUT_DIR / \"y_true_test.npy\")\n",
    "    y_pred = np.load(OUT_DIR / \"y_pred_test.npy\")\n",
    "    class_names = np.load(DATA_DIR / \"label_encoder.npy\", allow_pickle=True).tolist()\n",
    "\n",
    "    prefix = \"cnn_bilstm_bn_drop05_seed123\"\n",
    "\n",
    "    plot_training_curves_csv(log_csv, OUT_DIR, prefix)\n",
    "\n",
    "    labels = list(range(len(class_names)))\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        y_true, y_pred,\n",
    "        OUT_DIR / \"confusion_matrix_counts\",\n",
    "        class_names=class_names,\n",
    "        labels=labels,\n",
    "        normalize=False\n",
    ")\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        y_true, y_pred,\n",
    "        OUT_DIR / \"confusion_matrix_normalized\",\n",
    "        class_names=class_names,\n",
    "        labels=labels,\n",
    "        normalize=True,\n",
    "        show_counts=True,\n",
    "        min_show_pct=10.0\n",
    ")\n",
    "\n",
    "    print(\"Plots generated successfully.\")\n",
    "\n",
    "plot_results_only()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
